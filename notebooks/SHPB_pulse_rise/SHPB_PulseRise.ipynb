{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27594949-9b4d-4a50-9a9c-f3f4f7fc4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import re \n",
    "from datetime import datetime\n",
    "import pywt\n",
    "\n",
    "base_dir = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64744ce-3f82-4820-8062-df07adb20c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_data_files(base_dir):\n",
    "    \"\"\"\n",
    "    Recursively find all 'data' files (case-insensitive) within the given base directory.\n",
    "    Returns a list of tuples (folder_name, file_path).\n",
    "    \"\"\"\n",
    "    data_files = []\n",
    "\n",
    "    # Search for all files in the directory and filter those named \"binout\" (case-insensitive)\n",
    "    for file_path in Path(base_dir).rglob(\"*.txt\"):\n",
    "            folder_name = file_path.parent.name  # Extract folder name\n",
    "            data_files.append((folder_name, str(file_path)))\n",
    "\n",
    "    return data_files\n",
    "\n",
    "def find_pulse_edges(edges, signal, pulse_window):\n",
    "    \"\"\"\n",
    "    Identifies and classifies pulses using derivative-based edge detection and validates pulse windows.\n",
    "\n",
    "    Parameters:\n",
    "    edges (array-like): List of detected edge indices.\n",
    "    signal (array-like): The reference signal (e.g., SHPB strain gauge data).\n",
    "    pulse_window (float): Expected pulse duration (in index units).\n",
    "\n",
    "    Returns:\n",
    "    tuple: (List of valid pulse start indices, Dictionary of all pulse properties)\n",
    "    \"\"\"\n",
    "    rising_edges_start_idx = []\n",
    "    falling_edges_start_idx = [] \n",
    "    window_start_approx = []\n",
    "    window_end_approx = []\n",
    "    \n",
    "    edge_results = {\n",
    "        \"start\": [],\n",
    "        \"end\": [],\n",
    "        \"n_points\": [],\n",
    "        \"direction\": []\n",
    "    }\n",
    "    \n",
    "    if len(edges) == 0:\n",
    "        return window_start_approx, edge_results  # Return empty result if no edges detected\n",
    "\n",
    "    # Compute first derivative of the signal\n",
    "    derivative = np.gradient(signal)\n",
    "\n",
    "    # Sort edges to ensure order\n",
    "    edges = np.sort(edges)\n",
    "\n",
    "    # Group consecutive edges\n",
    "    grouped_edges = []\n",
    "    current_group = [edges[0]]\n",
    "\n",
    "    for i in range(1, len(edges)):\n",
    "        if edges[i] - edges[i - 1] <= 2:  # Allowing small gaps (adjustable)\n",
    "            current_group.append(edges[i])\n",
    "        else:\n",
    "            grouped_edges.append(current_group)\n",
    "            current_group = [edges[i]]\n",
    "    \n",
    "    grouped_edges.append(current_group)  # Add last group\n",
    "\n",
    "    # Process grouped edges to extract pulse properties\n",
    "    for group in grouped_edges:\n",
    "        start_idx = group[0]\n",
    "        end_idx = group[-1]\n",
    "        n_points = len(group)\n",
    "\n",
    "        # Compute average derivative over the pulse range\n",
    "        avg_slope = np.mean(derivative[start_idx:end_idx])\n",
    "\n",
    "        # Direction is determined by the sign of the average derivative\n",
    "        if avg_slope > 0: \n",
    "            direction = 1\n",
    "            rising_edges_start_idx.append(start_idx)\n",
    "        else: \n",
    "            direction = -1\n",
    "            falling_edges_start_idx.append(start_idx)\n",
    "\n",
    "        # Store results\n",
    "        edge_results[\"start\"].append(start_idx)\n",
    "        edge_results[\"end\"].append(end_idx)\n",
    "        edge_results[\"n_points\"].append(n_points)\n",
    "        edge_results[\"direction\"].append(direction)\n",
    "\n",
    "    # **Improved Logic for Pulse Window Matching**\n",
    "    for rise_idx in rising_edges_start_idx:\n",
    "        # Find the closest falling edge that meets pulse window constraints\n",
    "        valid_falls = [\n",
    "            fall_idx for fall_idx in falling_edges_start_idx\n",
    "            if pulse_window * 0.90 <= np.abs(rise_idx - fall_idx) <= pulse_window * 1.30\n",
    "        ]\n",
    "\n",
    "        if valid_falls:\n",
    "            # Select the closest falling edge\n",
    "            best_fall_idx = min(valid_falls, key=lambda x: abs(rise_idx - x))\n",
    "            window_start_approx.append(min(rise_idx, best_fall_idx))  # Store the earlier index as the start\n",
    "            window_end_approx.append(max(rise_idx, best_fall_idx))\n",
    "\n",
    "    return window_start_approx, window_end_approx\n",
    "\n",
    "def extract_pulse_window(signal, signal_start_approx, signal_end_approx, pulse_points, pp_extra, negative = True):\n",
    "    \n",
    "    search_range = np.arange(int(signal_start_approx-(pulse_points*pp_extra)),\n",
    "                             int(signal_start_approx+(pulse_points*(1+pp_extra)))\n",
    "                             ,1)\n",
    "    \n",
    "    signal_subset = np.array(signal[search_range])    \n",
    "    signal_gradient = np.gradient(signal_subset)\n",
    "\n",
    "    if negative:\n",
    "        signal_start_slope = np.argmin(signal_gradient)\n",
    "        \n",
    "    else: \n",
    "        signal_start_slope = np.argmax(signal_gradient)\n",
    "        \n",
    "    signal_start_zero = np.where(np.isclose(signal_subset[:signal_start_slope], 0, atol=5e-5))[0][-1]\n",
    "    signal_end_zero = np.where(np.isclose(signal_subset[signal_start_slope:], 0, atol=11e-5))[0][0]\n",
    "    \n",
    "    window_range = np.arange(int(signal_start_zero), int(signal_start_slope + signal_end_zero), 1)    \n",
    "    extracted_signal = signal_subset[window_range]\n",
    "    time_start_idx = int(signal_start_approx-(pulse_points*pp_extra) + signal_start_zero)\n",
    "    \n",
    "    return extracted_signal, time_start_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b22b9858-af4a-40ca-bc2c-45eee8608280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 tests for analysis\n"
     ]
    }
   ],
   "source": [
    "data_files = find_data_files(base_dir)\n",
    "print(f\"Found {len(data_files)} tests for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d614d5a5-aed3-424b-9ab9-6c878eb1cb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic_Test01.txt not processed.\n",
      "list index out of range\n",
      "Elastic_Test02.txt not processed.\n",
      "list index out of range\n",
      "Elastic_Test03.txt not processed.\n",
      "list index out of range\n",
      "Elastic_Test04.txt not processed.\n",
      "list index out of range\n",
      "Elastic_Test05.txt not processed.\n",
      "list index out of range\n",
      "Elastic_Test06.txt not processed.\n",
      "list index out of range\n",
      "Elastic_Test10.txt not processed.\n",
      "list index out of range\n"
     ]
    }
   ],
   "source": [
    "wavelet = 'gaus1'\n",
    "scales = np.arange(1, 300, 2)  # Multi-scale analysis \n",
    "pulse_data_points = 9850 # from previous analysis in database \n",
    "\n",
    "pulse_rise_data = pd.DataFrame()\n",
    "\n",
    "for test_paths in data_files:\n",
    "    folder_date, data_path = test_paths\n",
    "\n",
    "    strain_data = pd.read_csv(data_path, sep=\"\\t\")\n",
    "    strain_data.drop(index=0, inplace=True)\n",
    "\n",
    "    incident_raw = strain_data[\"Channel A\"].astype(np.float32)\n",
    "    transmitted_raw = strain_data[\"Channel B\"].astype(np.float32)\n",
    "    time = strain_data[\"Time\"].astype(np.float32)\n",
    "\n",
    "    # Compute CWT\n",
    "    incident_coeffs, _ = pywt.cwt(incident_raw, scales, wavelet)\n",
    "    transmitted_coeffs, _ = pywt.cwt(transmitted_raw, scales, wavelet)\n",
    "\n",
    "    # Find strong edges by taking the absolute max of wavelet coefficients\n",
    "    incident_edges = np.where(np.abs(incident_coeffs).max(axis=0) > np.percentile(np.abs(incident_coeffs), 98.5))[0]\n",
    "    transmitted_edges = np.where(np.abs(transmitted_coeffs).max(axis=0) > np.percentile(np.abs(transmitted_coeffs), 98.5))[0]\n",
    "\n",
    "    incident_start_approx, incident_end_approx = find_pulse_edges(incident_edges, incident_raw,\n",
    "                                                              pulse_data_points)\n",
    "    transmitted_start_approx, transmitted_end_approx = find_pulse_edges(transmitted_edges, transmitted_raw ,\n",
    "                                                                        pulse_data_points)\n",
    "\n",
    "    dt = np.mean(np.diff(time))\n",
    "    try:\n",
    "        incident_start = np.where(np.isclose(incident_raw[:incident_start_approx[0]], 0, atol=0.3))[0][-1]\n",
    "        incident_pulse_gradient = np.gradient(incident_raw[incident_start:incident_start+pulse_data_points])\n",
    "        incident_min = np.argmin(incident_pulse_gradient)\n",
    "        incident_peak =  np.where(np.isclose(incident_pulse_gradient[incident_min:], 0, atol=5e-6))[0][0]\n",
    "        incident_rise_time = dt * (incident_min + incident_peak)\n",
    "        \n",
    "    \n",
    "        transmitted_start = np.where(np.isclose(transmitted_raw[:transmitted_start_approx[0]], 0, atol=0.3))[0][-1]\n",
    "        transmitted_pulse_gradient = np.gradient(transmitted_raw[transmitted_start:transmitted_start+pulse_data_points])\n",
    "        transmitted_min = np.argmin(transmitted_pulse_gradient)\n",
    "        transmitted_peak =  np.where(np.isclose(transmitted_pulse_gradient[transmitted_min:], 0, atol=5e-6))[0][0]\n",
    "        transmitted_rise_time = dt * (transmitted_min + transmitted_peak)\n",
    "    \n",
    "        results = pd.DataFrame({\n",
    "            \"Date\": [folder_date],\n",
    "            \"Test\": [data_path.split(\"\\\\\")[-1]],\n",
    "            \"Incident Rise Time (ms)\": [incident_rise_time],\n",
    "            \"Transmitted Rise Time (ms)\": [transmitted_rise_time]       })    \n",
    "\n",
    "        pulse_rise_data = pd.concat([pulse_rise_data, results], axis=0, ignore_index=True) \n",
    "    \n",
    "            # Create figure and axis\n",
    "        fig, ax = plt.subplots(figsize=(11, 6))\n",
    "        \n",
    "        # Plot raw signals\n",
    "        ax.plot(time, incident_raw, label=\"Incident\", color=\"royalblue\", linewidth=2)\n",
    "        ax.plot(time, transmitted_raw, label=\"Transmitted\", color=\"red\", linewidth=2)\n",
    "        \n",
    "        # Plot approximate start and end points\n",
    "        ax.scatter(time[incident_start], incident_raw[incident_start], color=\"purple\", s=100, label=\"Incident Start\",\n",
    "                   edgecolors=\"black\", zorder=4)\n",
    "        ax.scatter(time[incident_start + incident_min + incident_peak ], incident_raw[incident_start + incident_min + incident_peak], color=\"darkturquoise\",\n",
    "                   s=100, label=\"Incident End\", edgecolors=\"black\", zorder=4)\n",
    "        ax.scatter(time[transmitted_start], transmitted_raw[transmitted_start], color=\"plum\", s=100, label=\"Transmitted Start\",\n",
    "                   edgecolors=\"black\", zorder=4)\n",
    "        ax.scatter(time[transmitted_start + transmitted_min + transmitted_peak], transmitted_raw[transmitted_start+ transmitted_min + transmitted_peak],\n",
    "                   color=\"salmon\", s=100, label=\"Transmitted End\", edgecolors=\"black\", zorder=4)\n",
    "        \n",
    "        # Customize plot appearance\n",
    "        ax.set_title(\"Rise Time Calculations on Raw Pulse Data\", fontsize=18)\n",
    "        ax.set_xlabel(\"Time (ms)\", fontsize=14)\n",
    "        ax.set_ylabel(\"Voltage\", fontsize=14)\n",
    "        ax.grid(True, linestyle=\"--\", linewidth=0.5, color=\"grey\")\n",
    "        ax.legend(fontsize=12, frameon=True, edgecolor=\"black\")\n",
    "    \n",
    "        figure_folder = \"figures\"\n",
    "        os.makedirs(figure_folder, exist_ok=True)\n",
    "        plt.savefig(os.path.join(figure_folder, folder_date + \"_\"+data_path.split('\\\\')[-1].split('.txt')[0] + \".png\"))\n",
    "        plt.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(data_path.split('\\\\')[-1] + \" not processed.\")\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68b14a99-952a-4b24-b64c-bf77d4276c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulse_rise_data.to_csv( \"pulse_rise_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14266189-c602-4a10-b097-a63045b0a3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
